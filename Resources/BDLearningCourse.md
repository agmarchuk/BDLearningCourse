# Учебный курс "Алгоритмы и технологии обработки больших данных"

Марчук А.Г., д.ф.-м.н., профессор

## Введение

Цели курса – дать студентам знания, умения и навыки, необходимые для понимания и работы с большими базами данных. Для продвинутых студентов этот курс позволит начать работу по осваиванию программирования специализированных баз данных.

В учебном пособии активно используется авторская разработка: библиотека PolarDB, предназначенная для создания специализированных и универсальных баз данных и СУБД. Практическая часть курса выполнена в среде программирования .NET Core на языке программирования C#. Используемые компоненты PolarDB присутствуют в разделе DLLs и доступны только в 64-разрядном варианте.

## Task01_HelloBigData: Файл, как основа работы с хранимыми данными. Моя первая база данных на C#

Традиционным началом для изучения программных технологий, является написание простейшего приложения-приветствия. Мы пойдем дальше, попробуем «прикоснуться» к проблематике больших данных через написание достаточно простой программы.  Одновременно, будем осваивать использование работу с файлами и стримами (streams). В конечном счете, именно файл почти всегда является носителем сохраняемых данных вне зависимости от их объема. 

Все задание можно выполнить в VisualStudio. Однако, для того, чтобы лучше понимать процессы формирования и исполнения кода, рекомендуется выполнить это задание в командном интерфейсе автономной среды .NET Core. Интерфейс достаточно дружественен и проблем с выполнением простых программ, как правило, не возникает. 

Если Вы искушенный в .NET Core программист, то прошу прощения за известные технологические детали, если Вы новичок, то прошу прощения за упущенные в объяснении детали, которые Вам придется осваивать самостоятельно. 

Командный интерфейс, автономной среды .NET Core доступен сразу после установки этой системы. Собственно команды набираются в любом интерпретаторе командных строк, напр. встроенном в Windows. Стандартными средствами cd, надо «добраться» до директории, в которой Вы хотите работать, создать там директорию, напр. mkdir HelloWorld, для выполнения задания, перейти вовнутрь. Дальше начинаются содержательные действия. Главная программа, которую надо запускать в командной строке – dotnet.

Запускаем:
```
dotnet new console
```
В директории появится файл .csproj проекта и тестовая программа Program.cs.  Далее, нужно обновить библиотечные файлы
```
dotnet restore
```
После этого можно скомпилировать программу и исполнить ее
```
dotnet build 
dotnet run
```
Исполненная программа выдаст в консоль Hello World!
Дальше можно модифицировать программу Program.cs и добавлять новые модули. Для запуска, надо повторять Dotnet build Dotnet run, или можно только dotnet run. В этом случае, сначала программа будет компилироваться, а потом исполняться. Компиляция может выявить ошибку, об этом будет сказано в диагностическом сообщении и детали сообщения помогут Вам выявить и исправить ошибку. Комментарии будут на английском и обычно их не слишком сложно понять. Учите английский – это часть профессии программиста!

Такая программа слишком проста и мы сразу «двинемся» дальше – к большим данным. Можно производить редактирование программы Program.cs с помощью любого текстового редактора, но уже будет полезным осваивать специализированные средства. К таким относятся Visual Studio и Visual Code. Новичкам я рекомендую студию. Упомянутый проектный файл .csproj выполнен в формате Visual Studio и если студия у Вас загружена, можно из консоли запустить его, напр. start HelloWorld.csproj
Или можно запустить студию обычным образом и потом связать ее с созданными директорией и проектным файлом. Пробуйте.

Будем модифицировать программу в сторону работы с файлом. Для этого, полезно указать в ее начале программы то, что нам нужно соответствующее пространства имен. Начало программы теперь будет выглядеть так:
```
using System;
using System.IO;
```
Обратите внимание, что студия довольно хорошо подсказывает при наборе текста. Поэтому, если не торопиться, можно увидеть массу полезной информации. Это не заменяет документации, но очень помогает тому, кто такую документацию читал, но подзабыл детали. 

Первая часть задания будет заключаться в том, чтобы создать файл и наполнить его данными. Файл создается одной строчкой типа:
```
    FileStream fs = File.Open("data.bin", FileMode.OpenOrCreate);   
```
Добавив строчку в программу и исполнив ее, мы увидим, что в рабочей директории появился файл нулевой длины с указанным именем. При повторном исполнении, ничего не меняется, строчка работает также как способ подсоединения к файлу. Что мы получили в программе? Мы получили поток байтов, доступный для записи и чтения. Будем осваивать бинарные запись и чтение (бинарный – это не текстовый, детали разницы сейчас не существенны). Бинарные запись и чтения выполняются через Write() и Read(), которые не очень удобны для наших текущих целей, поэтому сразу освоим специальные средства для этого. Это BinaryWriter и BinaryReader, создаваемые на основе стрима, в данном случае , файлового стрима. Сначала нам нужен писатель, добавляем строчку:
```
    BinaryWriter bw = new BinaryWriter(fs);  
```
Через райтер можно подряд писать значения разных типов C# просто добавляя через bw.Write(val). При этом, значение будет записано в поток байтов с занятием нужного количества следующих байтов. Например,  мы можем записать длинное целое bw.Write((long)333) и при этом, будет занято 8 следующих байтов. Для прозрачности, запишем МНОГО длинных целых, напр. 100 млн. Причем будем писать значения по порядку: 0, 1, 2, …
```
    long nelements = 100000000;
    for (long ii = 0L; ii < nelements; ii++) bw.Write(ii);
```
Программа выполнилась довольно быстро (у меня около 2.2 сек.). Посмотрим на результирующий файл. Он оказался несколько меньше, чем ожидалось: у меня 799 997 952 байта. Дело в том, что FileStream имеет буфер и буфер надо сбрасывать методом Flush(). Добавим строчку:
```
    fs.Flush();
```
Теперь все в порядке. Мы удивительно быстро создали примитивную базу данных, расположенную в файле. 

Вторая часть задания будет заключаться в имитации работы с базой данных. Работа будет заключаться в том, что по заданному случайным образом индексу, мы будем читать то длинное целое, которое ранее туда записали. Эдакий Random Access. Чтобы осуществлять обратное к записи действие, а именно чтение, надо создать бинарного читателя аналогично писателю:
```
    BinaryReader br = new BinaryReader(fs);
```
И с его помощью можно будет читать значения разных типов, напр. длинные целые. Но с какого места? С того, на котором стоит «головка» чтения, она же головка записи. Поэтому сразу прочесть ничего не получится (проверьте!), поскольку головка записи стоит в самом конце файла. Все очень просто: fs.Position = … установит эту головку туда, куда нам нужно. Причем позиция задается как двойное целое. На сначала, надо 
проверить на единичном чтении, что в файле правильные значения. Мы помним, что записывалось длинное целое, соответствующее номеру записи, проверочный фрагмент может быть:
```
    fs.Position = nelements * 2 / 3;
    long v = br.ReadInt64();
    Console.WriteLine($"v = {v}"); 
```
Шестерки покажут, что все получилось правильно. Единичная выборка выполняется слишком быстро, для того, чтобы засечь время выполнения, поэтому будем "прыгать" по файлу случайным образом и читать. И сравнивать с тем, что должно получиться. В итоге, напишем фрагмент типа:
```
    Random rnd = new Random();
    long nreads = 1000000;
    for (long ii = 0; ii < nreads; ii++)
    {
        long ind = rnd.Next((int)nelements);
        fs.Position = ind * 8;
        long val = br.ReadInt64();
        if (val != ind) throw new Exception($"Err: ind={ind} val={val}");
    }    
```
В котором мы не только выполняем требуемое действие, но и проверяем то, что ранее было записано нужное число. Обращаю Ваше внимание на то, что читаем мы не 100 миллионов раз, а только 1 миллион. Это потому что чтение или запись «подряд» гораздо быстрее чтения или записи по случайному индексу. У меня такой цикл чтений выполняется около 4 сек. Кстати, пора начать измерять временные интервалы. Предпочитаю делать это с помощью класса System.Diagnostics.Stopwatch – специализированного секундомера. Созданный объект запускается через метод Start() или Restart(), измерение интервала времени останавливается методом Stop(), после этого, в объекте можно взять измеренный интервал через напр. sw.ElapsedMilliseconds.

Вспоминаем, что мы создаем примитивную базу данных, а база данных должна хранить накопленные данные и после завершения программы, отключаем (напр. комментированием) фрагмент записи данных, оставляем только открытие файла и цикл чтения и убеждаемся, что программа работает. Если говорить в терминах доступа к базе данных, то получаются очень хорошие результаты. Однако, не спешите! Перезагрузите компьютер, запустите программу снова в режиме только чтения. Что получилось? Скорее всего, Вы не дождались окончания работы программы. Наверное, Вы решили, что программа остановилась. Но нет, она работает. Приблизительно в тысячу раз медленнее, чем ранее! В чем дело? Дело в том, что доступ к файлу в современных операционных решениях осуществляется с использованием системного кеша. При записи в файл, его странички «осели» в кеше и выборка происходила довольно быстро. Перезагрузка машины привела к очищению системного кеша, поэтому доступ к содержимому диска стал выполняться в темпе работы диска. А это, для HDD – приблизительно 100 (Random Access) доступов в секунду. Замерьте время последнего теста для разумного количества испытаний и убедитесь, что приблизительно эти скорости и получаются. Этот эффект называется «холодая» база данных, а способ ее активизации – «разогревом». Как правило, при достаточно длительной работы базы данных, она переходит из холодного в разогретое состояние естественным путем. Но не всегда этот способ является быстрым. Зная природу охлаждения и разогрева данных, легко предложить свой способ эффективного разогрева нашей базы данных. Достаточно напр. предварительно прочитать данные (и ничего с ними не делать), для того, чтобы все восстановилось. Для эксперимента, можно скопировать напр. средствами файл-менеджера файл базы данных (после этого, копию можно уничтожить) – это даст желаемый разогрев. Или можно выполнить фрагмент программы:
```
    byte[] buffer = new byte[1000000];
    int nblocks = (int)(nelements * 8 / buffer.Length);
    for (int i = 0; i < nblocks; i++) fs.Read(buffer, 0, buffer.Length);
```
Эксперименты с разогревом показывают, что несмотря на то, что разогрев (почему-то) работает дольше, чем просто запись (у меня 9 сек.), после этого, проблем с производительностью не наблюдается. 

Однако, разогрев будет «работать» только до определенного размера, на моем компьютере – до приблизительно 1 млрд. элементов (по 8 байтов). Это потому, что оперативная память, используемая для системного кеширования работы с файлами, у меня как раз 8 Гб. На самом деле, переход от кеширования к некешированию происходит довольно резко. На моем компьютере, 10 тыс. доступов к анализируемой базе данных в 700 млн. элементов выполняется за 50-80 мс., а к базе данных в 1 млрд. элементов – 31 сек.! 

Мы вышли на принципиальные моменты. Можно попробовать сделать следующие выводы:
1)	Для базы данных существенным фактором, влияющим на скорость работы с данными, является кеширование. Имеется системное кеширование, которое позволяет делать системы со скоростью около 100 тыс. доступов в сек. 
2)	При превышении объема активных данных размера ОЗУ, схемы кеширования становятся неэффективными и скорость доступа будет определяться скоростью доступа к внешнему носителю. Для HDD это около 100 доступов в сек. 
3)	Кроме оптимизации алгоритмов работы с данными, очень важным является эффективная реализация разогрева данных, т.е. перевода активной части данных в кеш.   
  
P.S. Не забудьте уничтожить файл с данными, он все-же под гигабайт!

## Task02_SQLite: Осваиваем SQL в варианте SQLite

В настоящее время, подавляющее число баз данных делаются как связанные реляционные таблицы и погружаются
в реляционные СУБД. Эти СУБД концентрируют в себе труд множества разработчиков, иногда - несколько поколений разработчиков, являются эффективными промышленными решениями. Некоторая проблема стандартных СУБД заключается в том, что они универсальны, расчитаны на приенение в очень разных условиях, а поэтому 
не очень позволяют получать предельное по качеству решение для специальных задач или условий применения. 
В частности, эффективность универсальных решений может быстро деградировать при увеличении размеров или
сложности данных. 

Мы познакомимся с СУБД SQLite, про которую авторы говорят, что на ней реализована большая (с ударением на первый слог) часть баз данных в мире. Это похоже на правду, поскольку другие СУБД, расчитаны на серверное использование, а эта - очень компактная и может эффективно работать в составе практически любого решения как подключаемая библиотека. В частности, SQLite используют в приложениях для мобильных устройств (вот и most part!). 

SQLite является свободно распространяемым программным обеспечением (ПО), более того, с открытым кодом. Последнее нам не понадобится. SQLite поддерживается через сайт sqlite.org, где можно найти собранные варианты для разных платформ и документацию для грамотного пользования. Для использования совместно с .NET имеется адаптированное для .NET решение, его можно скачать и подключать к проекту как другие библиотечные слои. Но более удобным, является использование NuGet - технологии динамического подключения к специально оформленным модулям. NuGet дает возможность не только разово скачать желаемую систему, но и будет заботиться об обновлениях этой системы. 

Заведем проект. Кстати о названии проектов. Категорически не приветствуюется называть проекты типа ConsoleProj1 и помечать его куда попало. Это же касается и других идентификаторов. Ленность мысли, "двигающая" вами, ни к чему хорошему не приведет. Важно называть объекты мнемонично и в системе соглашений имеющейся в проекте, в системе программирования. Например, в проектах на C# принято названия пространств имен, классов, методов (и проектов) начинать с большой буквы, а названия переменных - с маленькой. Но существеннее именно мнемоничность. Экономьте свои и чужие усилия по написанию и чтению кода. Ответы на вопросы "как же я назвал?" или "что бы это значило?", можно существенно облегчить через общие правила называния и закладываемую мнемонику. Кроме того, небольшое умственное усилие по выдумыванию "хорошего" названия, будут постоянным тренингом ваших мозгов. 

Вернемся проекту. Я не умею запускать SQLite совместно с .NET Core, поэтому рекомендую использовать более старый, но стандартынй вариант проекта, поищите "Консольное приложение (.NET Framework)". Создайте его, проверьте, что оно работает. Сразу загрузим библиотеку SQLite. Для этого, (через правую кнопку) выходим на "Управление проектами NuGet", устанавливаем резим "Обзор" и ищем SQLite, находим System.Data.SQLite - это то, что надо, там около полутора миллионов скачиваний, устанавливаем. Куда-то это скачивается, нам не важен ни состав пакета ни место расположения, все это не сложно выяснить для тех,кому это интересно. Уже можно пробовать. 

Добавим используемые пространства имен:
```
using System.Data.SQLite;
using System.Data.Common;
```
База данных SQLite создается и развивается в файле, если файла нет, нужно его создать.
```
    string path = "../../../";
    string filename = path + "databases/test.db3";
    if (!System.IO.File.Exists(filename))
    {
        SQLiteConnection.CreateFile(filename);
    }
```
Подумайте над тем, в каком месте создается файл базы данных, создайте его. Проверьте работу, убедитесь, что файл создается. Ключевую роль в работе с базой данных, играет connection (коннектор, адаптер, соединитель). Заметим, что то, что было написано не порождает объекта, через который можно будет работать база данных. Создадим такой объект connection:
```
    DbProviderFactory factory = new SQLiteFactory();
    DbConnection connection = factory.CreateConnection();
    connection.ConnectionString = "Data Source=" + filename;
```
Коннектор сам подключится с базе данных через указание строки подключения. Работа с базой данных, как уже было сказано, выполняется через connection, причем для отдельного блока работы надо connection открыть, а по завершении - закрыть. Между этими "скобками" задаются действия. 

Будем создавать базу данных, состоящую из одной таблицы persons. Сначала почистим базу данных конструкцией DROP TABLE persons;
```
    connection.Open();
    DbCommand comm = connection.CreateCommand();
    comm.CommandText = @"DROP TABLE persons;";
    try { comm.ExecuteNonQuery(); }
    catch (Exception ex) { Console.WriteLine($"Warning in DROP section {ex.Message}"); }
    connection.Close();
```
 У персоны (у отдельной записи) есть ключевой целочисленный идентификатор, строковое имя, целочиленный возраст. 
```
    connection.Open();
    comm.CommandText =
    @"CREATE TABLE persons (id INTEGER PRIMARY KEY ASC, name TEXT, age INTEGER);";
    try { comm.ExecuteNonQuery(); }
    catch (Exception ex) { Console.WriteLine($"Warning in CREATE TABLE section {ex.Message}"); }
    connection.Close();
```
При первом запуске, команда DROP TABLE "ругнется", это нормально. Но потом уже будет что уничтожать, поскольку таблица персон создана. Теперь надо загрузить базу данных тестовыми данными. Изолируя каждую команду скобками открытия и закрытия, получаем что-то вроде:

```
    int npersons = 100;
    for (int i = 0; i < npersons; i++)
    {
        connection.Open();
        comm = connection.CreateCommand();
        comm.CommandText = "INSERT INTO persons VALUES (" + i + ",'" + i + "', 21);";
        Console.Write($"{comm.CommandText}");
        comm.ExecuteNonQuery();
        connection.Close();
    }
```

Следующий этап - выполнение запросов на получение данных. Б



```
    // Получение записи по ключу
    Random rnd = new Random();
    sw.Restart();
    for (long i = 0; i < 1000; i += 1)
    {
        connection.Open();
        var com = connection.CreateCommand();
        //int key = (int)(npersons * 2 / 3);
        int key = rnd.Next((int)npersons);
        com.CommandText = "SELECT * FROM persons WHERE id=" + key + ";";
        object[] res = null;
        var reader = com.ExecuteReader();
        int cnt = 0;
        while (reader.Read())
        {
            int ncols = reader.FieldCount;
            res = new object[ncols];
            for (int j = 0; j < ncols; j++) res[j] = reader.GetValue(j);
            cnt += 1;
        }
        if (cnt == 0) { Console.WriteLine("no solutions. key = {key}"); }
        else if (cnt > 1) { Console.WriteLine("multiple solutions. key = {key} cnt = {cnt}"); }
        //Console.WriteLine($"{key} => {res[0]} {res[1]} {res[2]}");

        reader.Close();
        connection.Close();
    }
    sw.Stop();
    Console.WriteLine($"duration {sw.ElapsedMilliseconds}");
```
По сравнению с записью и чтением в файл из файла, временные характеристики формирования базы данных и выполнения выборок, выглядят слабыми, а по записи данных (100 записей за 19 секунд!) - удручающими. В чем дело? В транзакциях. Про возможности использовать более эффективную схему вычислений, в которой транзакции не мешают, а помогают вычислениям, мы поговорим позже, а пока подумаем о том, какими другими способами можно ускорить хотя бы ввод данных. Главный способ - группирование запросов. Это общее решение - чем больше удается объединить элементов запросоа или запросов в одном SQL-запросе, тем лучше. В некоторых случаях это не так, но сейчас это не существенно. На сначала попробуем сгруппировать команды ввода под одним открытым connection'ом. Легко можно перенести скобки открытия и закрытия соединения за цикл и попробовать выполнить ввод. Попробовали - никакого эффекта. Не суть важно почему так, продолжим исследование. Существенно больших результатов можно достигнуть группируя единичные операторы ввода INSERT в групповой оператор INSERT INTO persons VALUES (...),(...),...;.
Вряд ли можно "загнать" один оператор весь поток ввода, но вводить группами по сколько-то сотен или тысяч можно. Эффект - очень заметный и практически линейный. И все же это не самый лучший способ оптимизации, тем более, что для других операторов, групповой конструкции может не оказаться или она может быть неэффективной. Вернемся к транзакциям.   

Транзакция - это последовательность действий, в частности - одно действие, защищенных от взаимодейстия с другими действиями. Другое свойство транзакции - если транзакция не могла закончиться успешно, СУБД автоматически восстанавливает состояние, которое было до начала попытки выполнения транзакци. Самый простой способ защиты действий - последовательное выполнение. Но в "стандартных" для сервера данных условиях, когда транзакции "сыпятся" на сервер асинхронно, приходится специально защищать эти транзакции специальным образом. Почему нельзя просто упорядочить транзакции по времени и не выполнять их последовательно? Можно, но это может оказаться неэффективно. Действительно, самая массовая в практике транзакция отдельная выборка по SELECT. В простом случае, она выполняется быстро, но если асинхронно в потоке есть сложные, медленные транзакции, хочется не слишком задерживать простые быстрые дожидаясь окончания медленных.

Сейчас нам транзакции нужны для вполне определенного дела - группирования действий в единое и, в этом случае, мы вполне можем мыслить последовательным потоком команд доступа к данным. Но как это реализовать? В SQL базах данных имеется методика реализации группы действий в рамках одной (большой) транзакции. Суть методики заключается в том что кроме объекта команды (класса DbCommand) явно создается объект класса DbTransaction, транзакция открывается (transaction.Open()) и "подклеивается" к команде. Далее, можно многократно задавать текст команды и исполнять ее. В конце, транзакцию надо закрыть выполнив Commit().  

Попробуем. У нас довольно плохо с вводом данных, даже в случае группирования команд INSERT. Начнем с этого места. В принципе, получается прозрачный код обработки, а именно:
```
    connection.Open();
    DbCommand runcommand = connection.CreateCommand();
    runcommand.CommandType = CommandType.Text;
    DbTransaction transaction = connection.BeginTransaction();
    runcommand.Transaction = transaction;
    for (int i = 0; i < nelements; i += 1)
    {
        runcommand.CommandText = "INSERT INTO persons VALUES (" + i + "' + i + "', 21);";
        runcommand.ExecuteNonQuery();
    }
    Console.WriteLine();
    loadtransaction.Commit();
    connection.Close();
```
Внимательно изучите код, прежде, чем вносить его в программу. Все просто, но нетривиально. После модификации фрагмента ввода, Эта часть программы сильно ускоряется. Теперь 100 тыс. записей загружаются за 0.7 сек., а 1 млн. - за 6 сек. То же самое можно сделать и во фрагменте выборки данных по случайно задаваемым ключам. Ускорение будет не столь драмматическим, но также вполне заметным. У меня, базовый вариант дает 300 мс. на 1000 запросов, если вынести открытие/закрытие коннектора за цикл, получается 100 мс., если использовать транзакцию - 35 мс. 

Вообще, измерение времени выполнения тех или иных действий - дело непростое. Сказываются и накладные расходы на организацию действия и попадание или непопадание данных в кеш. И что-то еще, включая способ трансляции и способ запуска. Тем не менее, измерение и сопоставление - это способ что-то утверждать о создаваемой или изучаемой программы. Но это измерение должно производиться правильно. Что это означает? В разных случаях разное, но главное, что методику тестирования и измерения надо обосновывать, обосновывать надо и применение методики к конкретным обстоятельствам. Современные системы полны инженерных особенностей, которые не лежат на поверхности и требуются усилия для того, чтобы провести грамотное тестирование и по измеренным результатам делать обоснованные выводы. 

### Тест "Фототека"
Теперь изучим и проанализируем тест "Фототека", предназначенный для тестирования и сопоставления разных решений в области работы с базами данных. Тест сделан намеренно максимально простым и легко воспроизводим в рамках практически любого решения. Тест сделан в парадигме связанных таблиц и приспособлен для максимально эффективной реализации на обычных SQL-платформах. 

Данные теста

База данных состоит из трех таблиц: персон, фотографий, отражений. Параметр тестового набора - количество записей в таблице персон или просто количество персон npersons. Количество фотографий - npersons * 2. Количество отражений npersons * 6. Все таблицы имеют идентификационное поле id, являющееся первичным ключом для таблицы, все ключи в одной таблице различны и в нашем построении - целочисленны. Таблица персон persons содержит три поля: целочисленный идентификатор id, строковое значение имени name, числовое (возможно целое или длинное целое или вещественное, это зависит от целей тестирования) значение возраста age. Таблица фотографий photos состоит из полей id и name,таблица отражений reflections содержит поля id, reflected, indoc. Причем два последних поля представляют внешние ссылки (external keys) на соответственно таблицу персон (отражаемое) и таблицу фотографий (отражение в документе). 

Таблица персон обычно заполняется следующим образом: в цикле по целочисленному i от 0 до npersons - 1, запись состоит из тройки (npersons-i, (npersons-i).ToString(), random.Next(150)). Практически также заполняется таблица фотографий, только их количество другое и третье поле отсутствует. Отражения заполняется по первому полю аналогично, а по второму и третьему, это псевдослучайная величина в диапазоне 0 - (npersons-1) и 0 - (nphotos-1) соответственно. В некоторых случаях, в таблице отражений колонка первичного ключа может отсутствовать - она в испытаниях, как правило, не используется. 

Тут надо обратить внимание на то, что диапазон идентификаторов не совпадает с интервалом 0 - nelements-1. Немного, всего на пару значений. Это сделано специально, для того, чтобы иметь варианты отсутствия записи с заданным (в стандартном диапазоне) ключа или отсутствия объекта ссылки для таблицы отражения. Такая особенность не является обязательной, а лишь где-то сможет помочь выявить не предусмотренные варианты обработки. Если система не позволяет иметь "висящие" ссылки, то лучше генерировать строгие данные, напр. для ключа формули может быть i или nelements - i - 1. Второй вариант предпочтительнее, поскольку ключи вводятся в обратном сортировочном порядке и создание внутреннего индекса скорее всего будет не столь тривиальной задачей, а поэтому выстраивание индекса по первичному ключу будет скорее всего заметно в измерениях.

Имена для персон и фотографий формируются следующим образом: это либо строковое значение идентификатора id или строковый код, а за ним идентификатор. Такая схема достаточно удобна, в частности, для проверки выдаваемых результатов. Кроме того, лексикографическое упорядочивание тестов чисел не совпадает с числовым упорядочиванием.

Тестовые процедуры

Тестирование и измерение проводятся по небольшому, но принципиальному спектру вопросов. Это - время загрузки, отдельно или вместе - время вычисления индексов. Это - время выборки записей по задаваемому случайным образом ключу, это - время выборки записей по задаваемому имени или части имени. Это - время вычисления "информационного портрета" персоны. Под этим вычислением понимается получение всех фотографий, на которых отражена персона с случайно задаваемым первичным ключем. Времена измеряются в миллисекундах или в секундах, для больших значений. Для "быстрых" действий по выборкам, измерения производится на подходящем количестве испытаний и приводятся к миллисекундам на 1 тыс. испытаний. 

Генератор псевдослучайных чисел должен работать без фиксированного "посева", иначе иногда возникают ситуации, что при повторных запусках, вычисления "пробегают" по относительно небольшому количеству сохраненных в кеше значений. 

Отдельная ситуация с поиском по имени. В принципе, есть два основных вариантов поиска, поиск по полному совпадению с образцом и поиск по частичному совпадению с образцом. Проблема в том, что часто это принципиально разные поиски. Поиск по полному совпадению может базироваться на эффективных решениях типа хеш-таблиц. Поиск по близости - это очень разные варианты. Причем большая часть вариантов трудны для индексации. Самый простой и не очень трудный - поиск по совпадению образца с началом строкового поля. Тогда нужно построить индекс, сортирующий лексикографически элементы таблицы и пользоваться дихотомией - рекурсивным бинарным прохождением индекса. Но дургие варианты похожести образца со строкой, напр. Contains(), уже плохо индексируются и, как правило, для них требуется сканирование данных. Сканированием назовем процесс перебора записей с последующий их фильтрацией. Часто используется еще похожесть через вычисление регуляного выражения. Способ универсальный, но кроме сканирования, трудно что-то предложить. 

Все измеряемые характеристики в том или ином варианте зависят от основного параметра - числа персон. Рекомендуемые значения параметра: 40 тыс., 400 тыс., 4 млн., 40 млн. Последнее количество - уже большие данные. То есть данные, не помещающиеся в оперативную память и которые поэтому очень сложно обрабатывать. Такое предпочтение (4) в скважности тестирования объясняется тем, что 40 тыс. в терминах триплетных высказываний - 1 млн. Соответственно 40 млн. - 1 млрд. триплетов, а это до сих пор является довольно большим количесовом для обработки. Есть еще дополнительные характеристики, которые имеет смысл иногда поизучать, но пока по ним не ведется общей статистики. Это - размер файла или файлов базы данных, предельный размер данных, которые системой обрабатываются, Нагрузка на ОЗУ и др.

После того, как мы определили тест "Фототека", следует попрактиковаться. В данном задании по изучению SQLite, требуется сформировать программу. В программе будет создаваться три таблицы, таблицы будут заполняться данными отталкиваясь от размера npersons, далее должны быть в цикле произведены вычисления записей по ключам, записей по именам, вычисление портретов. В принципе, вы все уже знаете, поэтому объяснять решение шаг за шагом нет необходимости, попробуйте выполнять задание самостоятельно. Причем самая желательная форма - не копируя участков предыдущего решения и не торопясь подгляывать в мое решение.  

## Task03_Polar.DB: Начинаем осваивать Поляр
В практической части данного курса будет использоваться библиотека работы с данными PolarDB или просто Поляр. Эта библиотека построена на небольшом количестве идей, принципов и решений, позволяет компактно и эффективно реализовывать специализированные построения.

Поляр построен на некотором представлении о типизации [], которое созвучно ряду других. Суть этого построения в том, что все рассматриваемые структурные объекты обладают внешним относительно себя типом и рассмотрение этих объектов корректно только в контексте его типа. В принципе, это как во многих других структурных построениях, напр. в C# можно написать оператор:
``
int[] arr = {1, 2, 3, 99};
``
При этом, int[] - определение типа структурного объекта, а справа имеется собственно структурный объект, точнее - его текстовое изображение, потому что в оперативной памяти, объект представляется по-другому. Мы можем изменить строчку на: 
``
double[] arr = {1, 2, 3, 99};
``
И это уже будет совсем другая структура!

Альтернативой такому подходу является структуризация в так называемых "безтиповых" языках программирования, напр. в JavaScript. При таком подходе, тип присутствует, но он "встроен" в структурное значение.

### Элементы теории поляровской структуризации

Структурное значение (structured value, поляровское структурное значение, p-value) - древовидное построение (значение), интерпретируемое в соответствии с заданным типом.

Тип (Type, поляровский тип, p-type) - древовидное построение, задающее интерпретацию для структурных значений. Может быть выражено как структурное значение. Тип может быть примитивным (атомарным) или конструируемым (составным).

Объект базы данных - сформированное в некотором рабочем поле или в хранилище структурное значение.

Объектное представление структурного значения - внутренняя конструкция в ОЗУ, вместе с типовым значением, задающая структурное значение. Объектное представление реализуется средствами какой-то (напр. .NET) системы программирования, доступно через какой-то язык программирования и служит связующим средством между программными объектами и объектами базы данных по следующей схеме: объект базы данных полностью или частично, отдельными полями, может быть реализован значениями объектного представления. Соответственно, возможно "чтение" объектов базы данных или их полей в объектное представление. И наоборот, возможна "запись" значений объектного представления в объекты базы данных или их поля.

Текстовая сериализация (текстовое представление) структурного значения - точные правила представления любого структурного значения последовательностью символов. Текстовое представление, совместно с явно или неявно определенным типом этого представления, есть структурное значение

Бинарная (байтовая) сериализация структурного значения - правила представления любого структурного значения в виде потока байтов. Бинарная сериализация осуществляется только в контексте типа сериализуемого или десериализуемого структурного значения.

Примитивные типы:

boolean, character, integer, longinteger, real - логическое, символьное, целое (32 разряда), длинное целое (64 разряда), число с плавающей точкой (64 разряда),
@byte - байт - 8-разрядный код,
none - множество значений, не содержащее ни одного элемента,
sstring - обычные строки объектно-ориентированного программирования (C#).

Конструируемые типы:

Запись (record) - фиксированный набор типизированных полей. Есть поля 0, 1, ... n-1, каждое из которых представляет значение заданного в определении записи типа. Количество полей - фиксировано, типы полей - фиксированы. Иногда полям сопоставляют имена, являющиеся идентификаторами.

Последовательность (sequence) - упорядоченный набор, состоящий из неопределенного (ноль или более) числа однотипных элементов.

Объединение (union) - значение, состоящее из тега и подзначения. Тег (динамически) определяет вариант типа для подзначения. Теги нумеруются, начиная с 0.

Объектное представление. Любое структурное значение может быть представлено в виде объекта по следующей схеме: примитивные типы реализуются значениями соответствующих системных типов - логического, целого, длинного целого, с плавающей точкой (double), символьного (char), байта, строки. Значения типа none представляются значениями null. Конструируемые типы представляются массивами object[], элементами которых будут подзначения структур. Запись - массив объектных значений своих элементов, последовательность - массив объектных значений элементов. Значение объединенного типа представляет собой массив из двух элементов. Первый элемент - целое значение тега. Второй элемент - объектное представление подзначения соответствующего тегу типа.

Примеры. Объектные значения (object)22, (object)"demo string", (object)true могут быть проинтерпретированы только как целое, строка и логическое. Объект new object[] {2, 33} может быт проинтерпретирован в зависимости от типа или как запись двух целых или как последовательность целых или как объединение с вариантом 2 и подзначением 33. Для последовательности записей, состоящих из строкового и целого, значением в объектном представлении может быть: new object { new object[] {"str1", 111}, new object[] {"str2", 222} }

Текстовая сериализация. Атомарные значения изображаются в виде текста: типа none - пустой строкой, типа boolean, character, integer, longinteger, real - традиционно, как напр. в C#. @byte изображается 16-ричным кодом, строка - как обычно (в C#). Запись изображается перечислением через запятую значений всех полей записи, начиная с нулевого и далее по порядку. Возможно использования имен полей (как в Паскале). Последовательность, изображается перечислением элементов через запятую, все перечисление (нуль или более элементов) помещается в квадратные скобки. Объединение изображается тегом - числом в диапазоне 0-255, следующим за ним символом ^ и далее идет изображение значения того типа, который динамически задан тегом. Значение может быть помещено в круглые скобки, это нужно для определенности разбора. По структурному значению и его типу однозначно, с точности до несущественных синтаксических элементов (пробелы, перевод строки, tab) и "лишних" скобок, определяется текстовая развертка. По корректной текстовой развертке и типу, однозначно определяется структурное значение.

Примеры. Для структурного значения типа последовательности записей строкового и целого полей, заданного в объектном виде как new object { new object[] {"str1", 111}, new object[] {"str2", 222} }, текстовая сериализация будет: [ {"str1", 111}, {"str2", 222} ].

Бинарная сериализация. Бинарная сериализация выполняется следующим образом: атомарные значения отображаются на последовательность байтов так, как определяется системой программирования C# через метод System.IO.BinaryWriter и двойственный ему System.IO.BinaryReader. Байт отображается в байт, целое в 4 байта, длинное целое - в 8 байтов, число с плавающей точкой в 8 байтов, значение типа none - в 0 байтов. Строка отображается сложнее. Сначала идет целое (4 байта) число, равное количеству символов в строке. Далее, если количество символов больше 0, то идут байты, сформированные по правилам UTF-8: byte[] info = new UTF8Encoding(true).GetBytes(str); Запись сериализуется поставленными "встык" сериализованными значениями полей. Последовательность вначале имеет 64-разрядное (8 байтов) целое, фиксирующее количество элементов последовательности (0+), а за ним подряд идут соответствующее количество значений элементов последовательности. Объединение реализуется постановкой 1 байта, который фиксирует код тега (0-255), за этим байтов непосредственно следует подзначение соответствующего тегу типа.

Язык определения типов. Поляровские типы задаются некоторыми формулами, задающими типовые (ударение на первый слог) значения. В принципе, эти значения можно рассматривать как обычные структурные значения, но эта ветвь в текущем варианте Поляра не реализована. К тому же, работать с заданием типа в таком представлении неудобно. Поэтому, для наглядности, в иллюстрациях используется специальный язык определения типов. Синтаксис языка в БНФ:
```
типовое_определение: имя_типа = типовая_формула ;
типовая_формула: none
     | bool | byte | char | int | long | float
     | { (имя поля : )? типовая_формула,.. }
     | [ типовая_формула ]
     | имя_тега ^ типовая формула
Синтаксические особенности и добавления. В формуле определения записи возможно использование имен полей. В случае, когда определяется последовательность записей, фигурные скобки внутри прямоугольных можно опустить.
```


```
```
