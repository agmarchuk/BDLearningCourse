# Учебный курс "Алгоритмы и технологии обработки больших данных"

Марчук А.Г., д.ф.-м.н., профессор

## Введение

Цели курса – дать студентам знания, умения и навыки, необходимые для понимания и работы с большими базами данных. Для продвинутых студентов этот курс позволит начать работу по осваиванию программирования специализированных баз данных.

В учебном пособии активно используется авторская разработка: библиотека PolarDB, предназначенная для создания специализированных и универсальных баз данных и СУБД. Практическая часть курса выполнена в среде программирования .NET Core на языке программирования C#. Используемые компоненты PolarDB присутствуют в разделе DLLs и доступны только в 64-разрядном варианте.

## Task01_HelloBigData. Файл, как основа работы с хранимыми данными. Моя первая база данных на C#

Традиционным началом для изучения программных технологий, является написание простейшего приложения-приветствия. Мы пойдем дальше, попробуем «прикоснуться» к проблематике больших данных через написание достаточно простой программы.  Одновременно, будем осваивать использование работу с файлами и стримами (streams). В конечном счете, именно файл почти всегда является носителем сохраняемых данных вне зависимости от их объема. 

Все задание можно выполнить в VisualStudio. Однако, для того, чтобы лучше понимать процессы формирования и исполнения кода, рекомендуется выполнить это задание в командном интерфейсе автономной среды .NET Core. Интерфейс достаточно дружественен и проблем с выполнением простых программ, как правило, не возникает. 

Если Вы искушенный в .NET Core программист, то прошу прощения за известные технологические детали, если Вы новичок, то прошу прощения за упущенные в объяснении детали, которые Вам придется осваивать самостоятельно. 

Командный интерфейс, автономной среды .NET Core доступен сразу после установки этой системы. Собственно команды набираются в любом интерпретаторе командных строк, напр. встроенном в Windows. Стандартными средствами cd, надо «добраться» до директории, в которой Вы хотите работать, создать там директорию, напр. mkdir HelloWorld, для выполнения задания, перейти вовнутрь. Дальше начинаются содержательные действия. Главная программа, которую надо запускать в командной строке – dotnet.

Запускаем:
```
dotnet new console
```
В директории появится файл .csproj проекта и тестовая программа Program.cs.  Далее, нужно обновить библиотечные файлы
```
dotnet restore
```
После этого можно скомпилировать программу и исполнить ее
```
dotnet build 
dotnet run
```
Исполненная программа выдаст в консоль Hello World!
Дальше можно модифицировать программу Program.cs и добавлять новые модули. Для запуска, надо повторять Dotnet build Dotnet run, или можно только dotnet run. В этом случае, сначала программа будет компилироваться, а потом исполняться. Компиляция может выявить ошибку, об этом будет сказано в диагностическом сообщении и детали сообщения помогут Вам выявить и исправить ошибку. Комментарии будут на английском и обычно их не слишком сложно понять. Учите английский – это часть профессии программиста!

Такая программа слишком проста и мы сразу «двинемся» дальше – к большим данным. Можно производить редактирование программы Program.cs с помощью любого текстового редактора, но уже будет полезным осваивать специализированные средства. К таким относятся Visual Studio и Visual Code. Новичкам я рекомендую студию. Упомянутый проектный файл .csproj выполнен в формате Visual Studio и если студия у Вас загружена, можно из консоли запустить его, напр. start HelloWorld.csproj
Или можно запустить студию обычным образом и потом связать ее с созданными директорией и проектным файлом. Пробуйте.

Будем модифицировать программу в сторону работы с файлом. Для этого, полезно указать в ее начале программы то, что нам нужно соответствующее пространства имен. Начало программы теперь будет выглядеть так:
```
using System;
using System.IO;
```
Обратите внимание, что студия довольно хорошо подсказывает при наборе текста. Поэтому, если не торопиться, можно увидеть массу полезной информации. Это не заменяет документации, но очень помогает тому, кто такую документацию читал, но подзабыл детали. 

Первая часть задания будет заключаться в том, чтобы создать файл и наполнить его данными. Файл создается одной строчкой типа:
```
    FileStream fs = File.Open("data.bin", FileMode.OpenOrCreate);   
```
Добавив строчку в программу и исполнив ее, мы увидим, что в рабочей директории появился файл нулевой длины с указанным именем. При повторном исполнении, ничего не меняется, строчка работает также как способ подсоединения к файлу. Что мы получили в программе? Мы получили поток байтов, доступный для записи и чтения. Будем осваивать бинарные запись и чтение (бинарный – это не текстовый, детали разницы сейчас не существенны). Бинарные запись и чтения выполняются через Write() и Read(), которые не очень удобны для наших текущих целей, поэтому сразу освоим специальные средства для этого. Это BinaryWriter и BinaryReader, создаваемые на основе стрима, в данном случае , файлового стрима. Сначала нам нужен писатель, добавляем строчку:
```
    BinaryWriter bw = new BinaryWriter(fs);  
```
Через райтер можно подряд писать значения разных типов C# просто добавляя через bw.Write(val). При этом, значение будет записано в поток байтов с занятием нужного количества следующих байтов. Например,  мы можем записать длинное целое bw.Write((long)333) и при этом, будет занято 8 следующих байтов. Для прозрачности, запишем МНОГО длинных целых, напр. 100 млн. Причем будем писать значения по порядку: 0, 1, 2, …
```
    long nelements = 100000000;
    for (long ii = 0L; ii < nelements; ii++) bw.Write(ii);
```
Программа выполнилась довольно быстро (у меня около 2.2 сек.). Посмотрим на результирующий файл. Он оказался несколько меньше, чем ожидалось: у меня 799 997 952 байта. Дело в том, что FileStream имеет буфер и буфер надо сбрасывать методом Flush(). Добавим строчку:
```
    fs.Flush();
```
Теперь все в порядке. Мы удивительно быстро создали примитивную базу данных, расположенную в файле. 

Вторая часть задания будет заключаться в имитации работы с базой данных. Работа будет заключаться в том, что по заданному случайным образом индексу, мы будем читать то длинное целое, которое ранее туда записали. Эдакий Random Access. Чтобы осуществлять обратное к записи действие, а именно чтение, надо создать бинарного читателя аналогично писателю:
```
    BinaryReader br = new BinaryReader(fs);
```
И с его помощью можно будет читать значения разных типов, напр. длинные целые. Но с какого места? С того, на котором стоит «головка» чтения, она же головка записи. Поэтому сразу прочесть ничего не получится (проверьте!), поскольку головка записи стоит в самом конце файла. Все очень просто: fs.Position = … установит эту головку туда, куда нам нужно. Причем позиция задается как двойное целое. На сначала, надо 
проверить на единичном чтении, что в файле правильные значения. Мы помним, что записывалось длинное целое, соответствующее номеру записи, проверочный фрагмент может быть:
```
    fs.Position = nelements * 2 / 3;
    long v = br.ReadInt64();
    Console.WriteLine($"v = {v}"); 
```
Шестерки покажут, что все получилось правильно. Единичная выборка выполняется слишком быстро, для того, чтобы засечь время выполнения, поэтому будем "прыгать" по файлу случайным образом и читать. И сравнивать с тем, что должно получиться. В итоге, напишем фрагмент типа:
```
    Random rnd = new Random();
    long nreads = 1000000;
    for (long ii = 0; ii < nreads; ii++)
    {
        long ind = rnd.Next((int)nelements);
        fs.Position = ind * 8;
        long val = br.ReadInt64();
        if (val != ind) throw new Exception($"Err: ind={ind} val={val}");
    }    
```
В котором мы не только выполняем требуемое действие, но и проверяем то, что ранее было записано нужное число. Обращаю Ваше внимание на то, что читаем мы не 100 миллионов раз, а только 1 миллион. Это потому что чтение или запись «подряд» гораздо быстрее чтения или записи по случайному индексу. У меня такой цикл чтений выполняется около 4 сек. Кстати, пора начать измерять временные интервалы. Предпочитаю делать это с помощью класса System.Diagnostics.Stopwatch – специализированного секундомера. Созданный объект запускается через метод Start() или Restart(), измерение интервала времени останавливается методом Stop(), после этого, в объекте можно взять измеренный интервал через напр. sw.ElapsedMilliseconds.

Вспоминаем, что мы создаем примитивную базу данных, а база данных должна хранить накопленные данные и после завершения программы, отключаем (напр. комментированием) фрагмент записи данных, оставляем только открытие файла и цикл чтения и убеждаемся, что программа работает. Если говорить в терминах доступа к базе данных, то получаются очень хорошие результаты. Однако, не спешите! Перезагрузите компьютер, запустите программу снова в режиме только чтения. Что получилось? Скорее всего, Вы не дождались окончания работы программы. Наверное, Вы решили, что программа остановилась. Но нет, она работает. Приблизительно в тысячу раз медленнее, чем ранее! В чем дело? Дело в том, что доступ к файлу в современных операционных решениях осуществляется с использованием системного кеша. При записи в файл, его странички «осели» в кеше и выборка происходила довольно быстро. Перезагрузка машины привела к очищению системного кеша, поэтому доступ к содержимому диска стал выполняться в темпе работы диска. А это, для HDD – приблизительно 100 (Random Access) доступов в секунду. Замерьте время последнего теста для разумного количества испытаний и убедитесь, что приблизительно эти скорости и получаются. Этот эффект называется «холодая» база данных, а способ ее активизации – «разогревом». Как правило, при достаточно длительной работы базы данных, она переходит из холодного в разогретое состояние естественным путем. Но не всегда этот способ является быстрым. Зная природу охлаждения и разогрева данных, легко предложить свой способ эффективного разогрева нашей базы данных. Достаточно напр. предварительно прочитать данные (и ничего с ними не делать), для того, чтобы все восстановилось. Для эксперимента, можно скопировать напр. средствами файл-менеджера файл базы данных (после этого, копию можно уничтожить) – это даст желаемый разогрев. Или можно выполнить фрагмент программы:
```
    byte[] buffer = new byte[1000000];
    int nblocks = (int)(nelements * 8 / buffer.Length);
    for (int i = 0; i < nblocks; i++) fs.Read(buffer, 0, buffer.Length);
```
Эксперименты с разогревом показывают, что несмотря на то, что разогрев (почему-то) работает дольше, чем просто запись (у меня 9 сек.), после этого, проблем с производительностью не наблюдается. 

Однако, разогрев будет «работать» только до определенного размера, на моем компьютере – до приблизительно 1 млрд. элементов (по 8 байтов). Это потому, что оперативная память, используемая для системного кеширования работы с файлами, у меня как раз 8 Гб. На самом деле, переход от кеширования к некешированию происходит довольно резко. На моем компьютере, 10 тыс. доступов к анализируемой базе данных в 700 млн. элементов выполняется за 50-80 мс., а к базе данных в 1 млрд. элементов – 31 сек.! 

Мы вышли на принципиальные моменты. Можно попробовать сделать следующие выводы:
1)	Для базы данных существенным фактором, влияющим на скорость работы с данными, является кеширование. Имеется системное кеширование, которое позволяет делать системы со скоростью около 100 тыс. доступов в сек. 
2)	При превышении объема активных данных размера ОЗУ, схемы кеширования становятся неэффективными и скорость доступа будет определяться скоростью доступа к внешнему носителю. Для HDD это около 100 доступов в сек. 
3)	Кроме оптимизации алгоритмов работы с данными, очень важным является эффективная реализация разогрева данных, т.е. перевода активной части данных в кеш.   
  
P.S. Не забудьте уничтожить файл с данными, он все-же под гигабайт!


